{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Defining machine learning models using numerical computation building blocks\n",
    "1. Linear regression\n",
    "2. Logistic regression\n",
    "\n",
    "Customizing machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "rng = np.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specification of the model:\n",
    "$y$ = $b$ + $w_1$$x_1$ + ... +  $w_p$$x_p$\n",
    "- $y$ is the regressed variable\n",
    "- $w$'s are the weights\n",
    "- $b$ is the bias term\n",
    "- $x$'s are the features used to model y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some toy data\n",
    "train_X = np.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y = np.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "n_samples = train_X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New concepts:\n",
    "1. Placeholders: https://www.tensorflow.org/api_guides/python/io_ops#Placeholders\n",
    "2. Variables: https://www.tensorflow.org/programmers_guide/variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the computational graph for linear regression with 1 explanatory variable\n",
    "# p = 1\n",
    "\n",
    "# Input to the graph\n",
    "y = tf.placeholder(dtype = tf.float32) # Placeholders - https://www.tensorflow.org/api_guides/python/io_ops#Placeholders\n",
    "x = tf.placeholder(dtype = tf.float32)\n",
    "\n",
    "# Model parameters are defined using variables\n",
    "# Variables - https://www.tensorflow.org/programmers_guide/variables\n",
    "# Variables retain their value even outside the bounds of a session's run call\n",
    "w = tf.Variable(initial_value = rng.randn(), name = \"weight\") \n",
    "b = tf.Variable(initial_value = rng.randn(), name = \"bias\")\n",
    "\n",
    "# Connecting up the nodes in our linear model\n",
    "# y = b + Wx\n",
    "\n",
    "prediction = tf.add(b, tf.multiply(w, x))\n",
    "\n",
    "# prediction holds the tensor that is the output of the operation add which takes tensors b, and the output of the multiply operation between the weight w, and the input x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is complete, but our computational graph is not yet complete. To complete the computational graph, we need to define a loss function and an optimization strategy to allow for the training of the free variables, $b$ and $w$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New concepts:\n",
    "3. reduce_sum operation: https://www.tensorflow.org/api_docs/python/tf/reduce_sum\n",
    "4. Gradient descent optimizer: https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining loss for our model\n",
    "# Loss is the mean squared error between actual $y$ and predicted $y$\n",
    "\n",
    "loss = tf.reduce_sum( input_tensor = tf.pow(prediction-y, 2))/(2*n_samples)\n",
    "# reduce_sum is a function to compute the sum across dimensions of a tensor. In this case, the input tensor is a 1 x n_samples dimensional tensor of the prediction errors corresponding to the training samples  \n",
    "# https://www.tensorflow.org/api_docs/python/tf/reduce_sum\n",
    "\n",
    "# We can use gradient descent to train our linear model\n",
    "# https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a complete computational graph. Each run of the optimizer takes one sample of X and Y as input, makes a prediction. The optimizer updates the free variables in its loss function based on the prediction for that input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need an operation to initialize our global  (w and b)\n",
    "init = init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 loss= 0.079028860 W= 0.2246135 b= 0.9811713\n",
      "Epoch: 0100 loss= 0.078795709 W= 0.22609936 b= 0.9704826\n",
      "Epoch: 0150 loss= 0.078589350 W= 0.22749679 b= 0.9604295\n",
      "Epoch: 0200 loss= 0.078406684 W= 0.22881103 b= 0.95097494\n",
      "Epoch: 0250 loss= 0.078245007 W= 0.23004703 b= 0.94208294\n",
      "Epoch: 0300 loss= 0.078101903 W= 0.23120938 b= 0.93372124\n",
      "Epoch: 0350 loss= 0.077975221 W= 0.23230262 b= 0.9258566\n",
      "Epoch: 0400 loss= 0.077863067 W= 0.23333083 b= 0.9184592\n",
      "Epoch: 0450 loss= 0.077763751 W= 0.234298 b= 0.9115017\n",
      "Epoch: 0500 loss= 0.077675819 W= 0.23520775 b= 0.9049575\n",
      "Epoch: 0550 loss= 0.077597961 W= 0.23606326 b= 0.8988027\n",
      "Epoch: 0600 loss= 0.077529006 W= 0.23686789 b= 0.89301443\n",
      "Epoch: 0650 loss= 0.077467956 W= 0.23762469 b= 0.8875697\n",
      "Epoch: 0700 loss= 0.077413879 W= 0.23833655 b= 0.8824489\n",
      "Epoch: 0750 loss= 0.077365980 W= 0.23900597 b= 0.8776329\n",
      "Epoch: 0800 loss= 0.077323578 W= 0.23963557 b= 0.8731038\n",
      "Epoch: 0850 loss= 0.077285990 W= 0.24022782 b= 0.8688434\n",
      "Epoch: 0900 loss= 0.077252731 W= 0.24078481 b= 0.8648359\n",
      "Epoch: 0950 loss= 0.077223219 W= 0.24130876 b= 0.8610668\n",
      "Epoch: 1000 loss= 0.077197067 W= 0.24180163 b= 0.8575213\n",
      "Optimization Finished!\n",
      "Training loss= 0.07719707 w= 0.24180163 b= 0.8575213 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x186ad945a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can now run the computational graph in a session\n",
    "training_epochs = 1000                      # We will run our model 1000 times\n",
    "display_step = 50                 # Display the loss every 50 runs\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        for (sample_x, sample_y) in zip(train_X, train_Y):\n",
    "            sess.run(optimizer, feed_dict={x: sample_x, y: sample_y})\n",
    "\n",
    "        #Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(loss, feed_dict={x: train_X, y:train_Y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"loss=\", \"{:.9f}\".format(c), \\\n",
    "                \"W=\", sess.run(w), \"b=\", sess.run(b))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_loss = sess.run(loss, feed_dict={x: train_X, y:train_Y})\n",
    "    print(\"Training loss=\", training_loss, \"w=\", sess.run(w), \"b=\", sess.run(b), '\\n')\n",
    "\n",
    "    #Graphic display\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(w) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a logistic regressor in a similar fashion as to how we created a linear regression computational graph.\n",
    "\n",
    "We will use the MNIST database of <a href=http://yann.lecun.com/exdb/mnist/>handwritten digits</a> for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression model specification:\n",
    "\n",
    "$y$ = $g$($\\Theta^{T}$ $X$) = $g$($\\sum_{i=0}^{n}$ $\\theta_{i}$ $x_{i}$) $\\text{ where }$ $x_0$ = 1\n",
    "\n",
    "- g is the <a href = https://en.wikipedia.org/wiki/Softmax_function>softmax function</a> which squashes any input to the 0-1 range\n",
    "\n",
    "- Tensorflow provides an implementation of the softmax function, which we can use.\n",
    "\n",
    "- The logistic regression model is trained by minimizing a cross-entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New concepts:\n",
    "5. Softmax : https://www.tensorflow.org/api_docs/python/tf/nn/softmax\n",
    "6. Reduce_mean : https://www.tensorflow.org/api_docs/python/tf/reduce_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the model\n",
    "# tf Graph Input\n",
    "x = tf.placeholder(dtype = tf.float32, shape = [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(dtype = tf.float32, shape = [None, 10]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(initial_value = tf.zeros([784, 10]))\n",
    "b = tf.Variable(initial_value = tf.zeros([10]))\n",
    "\n",
    "# Construct model\n",
    "prediction = tf.nn.softmax(tf.add(b, tf.matmul(x, W))) # Softmax\n",
    "\n",
    "# Minimize error using cross entropy loss\n",
    "# reduce_mean calculates the mean across dimensions of a tensor\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(prediction), axis=1))\n",
    "\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss= 0.000000000\n",
      "Epoch: 0002 loss= 0.000000000\n",
      "Epoch: 0003 loss= 0.000000000\n",
      "Epoch: 0004 loss= 0.000000000\n",
      "Epoch: 0005 loss= 0.000000000\n",
      "Epoch: 0006 loss= 0.000000000\n",
      "Epoch: 0007 loss= 0.000000000\n",
      "Epoch: 0008 loss= 0.000000000\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_loss = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            _, c = sess.run([optimizer, loss], feed_dict={x: batch_xs,\n",
    "                                                          y: batch_ys})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"loss=\", \"{:.9f}\".format(avg_loss))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for 3000 examples\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images[:3000], y: mnist.test.labels[:3000]}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
