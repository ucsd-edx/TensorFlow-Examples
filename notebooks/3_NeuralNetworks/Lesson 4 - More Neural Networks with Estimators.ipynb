{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Network Take 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Build a fully connected neural network with 2 hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" alt=\"nn\" style=\"width: 400px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Using TensorFlow's higher-level operations and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Estimators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- High level TensorFlow API that encapsulates\n",
    "    - Training\n",
    "    - Testing\n",
    "    - Prediction\n",
    "    - Export for model serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Two kinds of estimators\n",
    "    - Pre-made built-in estimators: DNNClassifier, LinearRegressor\n",
    "    - Custom estimators: written using Estimator API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"../../resources/img/estimator_types.png\" alt=\"nn\" style=\"width: 400px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Benefits of estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Estimator-based models are independent of operating environment\n",
    "    - local host\n",
    "    - GPUs\n",
    "    - CPU clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Simplify model sharing between deveopers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- State of the art models with high-level intuitive code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Built using tf.layers\n",
    "- Estimators build TF Graph automatically given a series of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Please go through https://www.tensorflow.org/programmers_guide/estimators for more advantages of using Estimators as described by the developers of TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## MNIST Dataset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flattened and converted to a 1-D numpy array of 784 features (28*28).\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Using the same parameters as when we built the neural network using the low-level TF API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "num_steps = 1000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using the Estimator API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Create an `input function`\n",
    "    - Supplies data for training, evaluation, prediction\n",
    "    - Yields pairs of:\n",
    "        - Python dict `features`: key = name of feature, value = array of feature values\n",
    "        - Array `label` : label for every example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "How the `input function` generates the `features` and `label` is up to the developer. TensorFlow developers recommend the use of the  TensorFlow's Dataset API. The Dataset API can parse in all kinds of data using a high level specification. This includes:\n",
    "- reading lines from a file\n",
    "- reading records from binary files\n",
    "- iterators\n",
    "- Initialize Dataset from  in-memory data\n",
    "\n",
    "The Dataset API can even read in large files in parallel and join them into a single stream. It is highly versatile and should definitely be used when training from data that resides on the disk. \n",
    "For more information, refer: https://www.tensorflow.org/get_started/datasets_quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To define our input function, we will use an inbuilt function `tf.estimator.inputs.numpy_input_fn` which can take in Numpy arrays and returns an input function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "From the documentation:\n",
    "\n",
    ">Returns input function that would feed dict of numpy arrays into the model.\n",
    "This returns a function outputting features and targets based on the dict of numpy arrays. The dict features has the same keys as the x. The dict targets has the same keys as the y if y is a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_input_fn(mode):\n",
    "    if mode == 'train':\n",
    "        return tf.estimator.inputs.numpy_input_fn(\n",
    "            x={'images': mnist.train.images}, y=mnist.train.labels,\n",
    "            batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "    elif mode == \"evaluation\":\n",
    "        return tf.estimator.inputs.numpy_input_fn(\n",
    "            x={'images': mnist.test.images}, y=mnist.test.labels,\n",
    "            batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "    If we had read the data from files, we need to create feature columns that describe how to use the input. \n",
    "    \n",
    "    Is it numeric? Categorical? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define the Model Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Model function is the beating heart of Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Has the following signature:\n",
    "```\n",
    "def my_model_fn(\n",
    "   features, # This is batch_features from input_fn\n",
    "   labels,   # This is batch_labels from input_fn\n",
    "   mode,     # An instance of tf.estimator.ModeKeys\n",
    "   params):  # Additional configuration\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "ModeKeys specify whether the model is being called for training, evaluation or prediction. This is useful for neural network architectures that vary between training and prediction, such as for models that make use of dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Workflow**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Specify additional calculations for:\n",
    "    - Training\n",
    "    - Prediction\n",
    "    - Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Defining a neural network function to use later\n",
    "- Input: feature dict\n",
    "- Output: Array of 10 logits "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "When using the Estimator API, it is recommended to use mid-level APIs such as Layers and Metrics in order to simplify the specification of our model. Fully connected hidden layers are implemented in `tf.layers` as a `Dense` layer. The Dense layer takes as input an incoming tensor, and the number of nodes in the Dense layer that we are specifying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def neural_net(x_dict):\n",
    "    x = x_dict['images']\n",
    "    layer_1 = tf.layers.dense(x, n_hidden_1)\n",
    "    layer_2 = tf.layers.dense(layer_1, n_hidden_2)\n",
    "    out_layer = tf.layers.dense(layer_2, num_classes)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Benefits of high level API:\n",
    "- Can encapsulate calculations as pre-defined layers. Other layers include:\n",
    "    - Convolution, Dropout, Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "def neural_net(x_dict):\n",
    "    # TF Estimator input is a dict, in case of multiple inputs\n",
    "    x = x_dict['images']\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.layers.dense(x, n_hidden_1)\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.layers.dense(layer_1, n_hidden_2)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.layers.dense(layer_2, num_classes)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implementing the Model function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First, prepare the output and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "logits = neural_net(features)\n",
    "pred_classes = tf.argmax(logits, axis=1)\n",
    "pred_probabilties = tf.nn.softmax(logits)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The model function returns an instance of `tf.estimator.EstimatorSpec`\n",
    "```\n",
    "class EstimatorSpec(\n",
    "    collections.namedtuple('EstimatorSpec', [\n",
    "        'mode', 'predictions', 'loss', 'train_op', 'eval_metric_ops',\n",
    "        'export_outputs', 'training_chief_hooks', 'training_hooks', 'scaffold',\n",
    "        'evaluation_hooks'\n",
    "    ])):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "If we are only interested in prediction or inference from the neural network, we do not need to backpropagate errors. In fact, we would not have the actual labels to calculate errors. \n",
    "\n",
    "In this case, we do not require the backpropagation part of the TF Graph. We can return an EstimatorSpec as soon as we make our predictions. \n",
    "\n",
    "For more complex DNN's there may be different model architectures for training as compared to evaluation or prediction. It is important to fully account for these cases in the specification of our model function by handling the branching cases. An example of a more complex DNN is a DNN that uses dropout layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Handle branching cases**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Prediction\n",
    "```\n",
    "if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Training and Evaluation\n",
    "\n",
    "```\n",
    "estim_specs = tf.estimator.EstimatorSpec(\n",
    "  mode=mode,\n",
    "  predictions=pred_classes,\n",
    "  loss=loss_op,\n",
    "  train_op=train_op,\n",
    "  eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "return estim_specs\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # Build the neural network\n",
    "    logits = neural_net(features)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n",
    "        \n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build and Use the Estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: D:\\Temp\\tmpxvj6xfyw\n",
      "INFO:tensorflow:Using config: {'_master': '', '_is_chief': True, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_model_dir': 'D:\\\\Temp\\\\tmpxvj6xfyw', '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002EF9D924908>, '_num_worker_replicas': 1, '_log_step_count_steps': 100, '_num_ps_replicas': 0, '_task_id': 0, '_service': None, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker'}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(model_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train the Model\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "The model can be trained using the Estimator's `train` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into D:\\Temp\\tmpxvj6xfyw\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2.4518557\n",
      "INFO:tensorflow:global_step/sec: 99.4813\n",
      "INFO:tensorflow:step = 101, loss = 0.33296615 (1.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.966\n",
      "INFO:tensorflow:step = 201, loss = 0.36804593 (0.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.652\n",
      "INFO:tensorflow:step = 301, loss = 0.3458166 (0.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.528\n",
      "INFO:tensorflow:step = 401, loss = 0.12781583 (0.957 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.074\n",
      "INFO:tensorflow:step = 501, loss = 0.33862978 (0.877 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.84\n",
      "INFO:tensorflow:step = 601, loss = 0.301341 (0.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.889\n",
      "INFO:tensorflow:step = 701, loss = 0.3442419 (0.918 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.168\n",
      "INFO:tensorflow:step = 801, loss = 0.33781174 (0.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.845\n",
      "INFO:tensorflow:step = 901, loss = 0.38626903 (0.919 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into D:\\Temp\\tmpxvj6xfyw\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.21108991.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x2ef9d9245c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fn = get_input_fn('train')\n",
    "model.train(input_fn, steps=num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The model can be trained using the Estimator's `evaluate` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Remember, we need the evaluation input function when we test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-23-06:23:20\n",
      "INFO:tensorflow:Restoring parameters from D:\\Temp\\tmpxvj6xfyw\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-23-06:23:21\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9181, global_step = 1000, loss = 0.2829952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9181, 'global_step': 1000, 'loss': 0.2829952}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_input_fn = get_input_fn('evaluation')\n",
    "model.evaluate(evaluate_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predict using the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:\\Temp\\tmpxvj6xfyw\\model.ckpt-1000\n",
      "Model predictions are  [7, 2]\n",
      "Model predictions are  [1, 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2efa0046908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_images = 4\n",
    "\n",
    "actual_labels = mnist.test.images[:n_images]\n",
    "predictions = list(model.predict(evaluate_input_fn))\n",
    "\n",
    "# Display\n",
    "f = plt.figure(figsize=(6,3))\n",
    "for i in range(n_images):\n",
    "    sp = f.add_subplot(2, 2, i+1)\n",
    "    sp.axis('Off')\n",
    "    plt.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
    "print('Model predictions are ' ,predictions[:2])\n",
    "print('Model predictions are ' ,predictions[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convolutional Neural Networks Using Estimators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>![CNN](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for our CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 2000\n",
    "batch_size = 128\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.25 # Dropout, probability to drop a unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement a ConvNet function using Layers API\n",
    "2. Define model in terms of ConvNet function and input_fn\n",
    "3. Build Estimator\n",
    "4. Train, Evaluate, Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ConvNet Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: \n",
    "- x_dict -- dict\n",
    "- n_classes -- int\n",
    "- dropout -- boolean\n",
    "- reuse -- boolean\n",
    "- is_training -- boolean\n",
    "\n",
    "Output: logits -- array of `n_classes` logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is dropout?\n",
    "\n",
    "Dropout is a technique developed in 2014 to \"learn better by learning less\". A dropout layer between two Dense layers would not permit the forward or backward flow of information with a pre-defined probability at training time. In other words, Dropout randomly drops neural units in the layers that sandwich the Dropout layer during training. The learned wisdom behind Dropout is that it aids in regularization by forcing the Neural network to learn without overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../../resources/img/Dropout.png\" alt=\"nn\" style=\"width: 400px;\"/>\n",
    "Srivastava, Nitish, et al. ”Dropout: a simple way to prevent neural networks from\n",
    "overfitting”, JMLR 2014</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At test time, all neurons in the network are active. So the computational graph varies between the training and testing phase, however the weights applied at each neuron remain the same. \n",
    "\n",
    "TensorFlow provides support to maintain the weights between computational graphs using a `reuse` flag when we enclose a Graph in a predefined scope.\n",
    "```\n",
    "with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input tensor has the shape `784 x batch_size`.\n",
    "\n",
    "We should reshape this tensor so that the ConvNet can learn filters that are spatially aware. We'll reshape it to match the picture's format: `Height x Width x Channel`.\n",
    "\n",
    "```x = tf.reshape(x, shape=[-1, 28, 28, 1])```\n",
    " \n",
    "Tensor input is now 4-D: `Batch Size, Height, Width, Channel`\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "263px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "251px",
    "left": "1px",
    "right": "20px",
    "top": "135px",
    "width": "212px"
   },
   "toc_section_display": "none",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
